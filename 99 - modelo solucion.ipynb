{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Santiagohvilla/Proyecto_IA-2025_2/blob/Entregas/99%20-%20modelo%20solucion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIoeO3ED3NGL"
      },
      "source": [
        "# MODELO SOLUCION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZtiGCm5t3NGX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c udea-ai-4-eng-20252-pruebas-saber-pro-colombia"
      ],
      "metadata": {
        "id": "S368LI-t5qvB",
        "outputId": "db5972b9-0e22-4f01-f403-e41252383ae1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 4, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/__init__.py\", line 6, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 434, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.config/kaggle. Or use the environment method. See setup instructions at https://github.com/Kaggle/kaggle-api/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip udea-ai-4-eng-20252-pruebas-saber-pro-colombia"
      ],
      "metadata": {
        "id": "IVQUJlCU5xQL",
        "outputId": "7711b902-3313-445e-e83b-7a950f314d73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open udea-ai-4-eng-20252-pruebas-saber-pro-colombia, udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip or udea-ai-4-eng-20252-pruebas-saber-pro-colombia.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"train.csv\")\n",
        "d = df.drop(columns=['F_TIENEINTERNET.1'])"
      ],
      "metadata": {
        "id": "66eLQ6FH8sjK",
        "outputId": "9f2db486-8433-4196-bf92-b479421c8d1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1898525092.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'F_TIENEINTERNET.1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d1=d.copy()\n",
        "# Convertir a mayúsculas y eliminar acentos/caracteres especiales y espacios extra\n",
        "d1['E_PRGM_ACADEMICO'] = d1['E_PRGM_ACADEMICO'].str.upper()\n",
        "d1['E_PRGM_ACADEMICO'] = d1['E_PRGM_ACADEMICO'].str.replace('Í', 'I', regex=False)\n",
        "d1['E_PRGM_ACADEMICO'] = d1['E_PRGM_ACADEMICO'].str.replace('Ú', 'U', regex=False)\n",
        "d1['E_PRGM_ACADEMICO'] = d1['E_PRGM_ACADEMICO'].str.replace('Á', 'A', regex=False)\n",
        "d1['E_PRGM_ACADEMICO'] = d1['E_PRGM_ACADEMICO'].str.replace('[^A-Z\\s]', '', regex=True) # Elimina caracteres no alfabéticos\n",
        "d1['E_PRGM_ACADEMICO'] = d1['E_PRGM_ACADEMICO'].str.replace('\\s+', ' ', regex=True).str.strip() # Elimina espacios dobles\n",
        "\n",
        "# Ingenierías\n",
        "ing_keywords = ['INGENIERIA', 'CIENTIFICA','BIOTECNOLOGIA','ANALISIS','OCEANOGRAFIA','GEOLOGA' ,'GEOGRAFIA','GEOLOGIA','ING', 'SOFTWARE', 'SISTEMAS', 'CONTROL', 'MECANICA', 'ELECTRONICA', 'CIVIL', 'INDUSTRIAL', 'BIOMEDICA', 'AERONAUTICA', 'TELECOMUNICACIONES']\n",
        "for kw in ing_keywords:\n",
        "    d1.loc[d1['E_PRGM_ACADEMICO'].str.contains(kw), 'E_PRGM_ACADEMICO'] = 'INGENIERIA'\n",
        "\n",
        "# Ciencias Sociales y Ley\n",
        "d1.loc[d1['E_PRGM_ACADEMICO'].str.contains('DERECHO|GOBIERNO|POLITICOS|CRIMINAL|CRIMINALISTICA|DESARROLLO|POLITICA|SOCIAL|JURISPRUDENCIA'), 'E_PRGM_ACADEMICO'] = 'CSOCIALES_Y_LEY'\n",
        "\n",
        "# Administración y Finanzas\n",
        "admin_keywords = ['ADMINISTRACION','ECONOMA','EMPRESAS','RELACIONES','RESTAURACION','ADMINISTRACIN','ECONOMICAS', 'GESTION','FINANCIERA', 'CONTADURIA', 'CONTADURÍA', 'ECONOMIA', 'MERCADEO', 'NEGOCIOS', 'COMERCIO', 'MARKETING', 'LOGISTICA', 'FINANZAS']\n",
        "for kw in admin_keywords:\n",
        "    d1.loc[d1['E_PRGM_ACADEMICO'].str.contains(kw), 'E_PRGM_ACADEMICO'] = 'ADMINISTRACION_Y_FINANZAS'\n",
        "\n",
        "# Salud y Ciencias Básicas\n",
        "salud_keywords = ['MEDICINA','OPTOMETRIA','GERONTOLOGIA','ESTADISTICA','ASTRONOMIA','ARQUEOLOGIA','FONOAUDIOLOGIA','PSICLOGA','FARMACIA','TERAPIA','FISICA','INSTRUMENTACION','QUIRURGICA','DIETETICA','NUTRICIN', 'CIENCIAS','MATEMATICAS','MATEMATICA','QUMICA', 'ENFERMERIA', 'PSICOLOGIA', 'SALUD', 'ODONTOLOGIA', 'FISIOTERAPIA', 'NUTRICION', 'BIOLOGIA', 'QUIMICA', 'FARMACEUTICA', 'BACTERIOLOGIA', 'MICROBIOLOGIA']\n",
        "for kw in salud_keywords:\n",
        "    d1.loc[d1['E_PRGM_ACADEMICO'].str.contains(kw), 'E_PRGM_ACADEMICO'] = 'SALUD_Y_CIENCIAS_BASICAS'\n",
        "\n",
        "# Educación\n",
        "d1.loc[d1['E_PRGM_ACADEMICO'].str.contains('LICENCIATURA|RECREACION|DEPORTE|FORMACION|DEPORTIVA|ENTRENAMIENTO|LITERATURA|FILOLOGIA|LENGUAS|TEOLOGIA|EDUCACION|PEDAGOGIA'), 'E_PRGM_ACADEMICO'] = 'EDUCACION'\n",
        "\n",
        "# Comunicación y Diseño\n",
        "com_dis_keywords = ['COMUNICACION','NARRATIVAS','ARCHIVISTICA','ANIMACIN','LITERARIOS','LITERARIA','FOTOGRAFIA','COMUNICACIN','RADIO', 'DISEO', 'MERCADOLOGIA', 'PERIODISMO', 'PUBLICIDAD', 'AUDIOVISUAL', 'DISEÑO', 'ARQUITECTURA', 'GRAFICO', 'CINE', 'TELEVISION']\n",
        "for kw in com_dis_keywords:\n",
        "    d1.loc[d1['E_PRGM_ACADEMICO'].str.contains(kw), 'E_PRGM_ACADEMICO'] = 'COMUNICACION_Y_DISENO'\n",
        "\n",
        "# Ciencias Agrarias y Ambientales\n",
        "agro_amb_keywords = ['AGRARIA', 'AGRO', 'CONSTRUCCION','ACUICULTURA','VETERINARIA', 'ZOOTECNIA', 'AMBIENTAL', 'ECOLOGIA', 'FORESTAL']\n",
        "for kw in agro_amb_keywords:\n",
        "    d1.loc[d1['E_PRGM_ACADEMICO'].str.contains(kw), 'E_PRGM_ACADEMICO'] = 'AGRARIAS_Y_AMBIENTALES'\n",
        "\n",
        "# Arte y Cultura (Debe ir al final para no sobreescribir Licenciaturas)\n",
        "d1.loc[d1['E_PRGM_ACADEMICO'].str.contains('MUSICA|BANDA|SOCIOLOGIA|ANTROPOLOGIA|CULTURAL|ARTE|DANZA|TEATRO|FILOSOFIA|HISTORIA'), 'E_PRGM_ACADEMICO'] = 'ARTE_Y_HUMANIDADES'\n",
        "\n",
        "# Turismo y Gastronomía\n",
        "d1.loc[d1['E_PRGM_ACADEMICO'].str.contains('TURISMO|URBANISMO|GASTRONOMA|TURISTICA|HOTELERIA|GASTRONOMIA|CULINARIA'), 'E_PRGM_ACADEMICO'] = 'TURISMO_Y_GASTRONOMIA'\n",
        "\n",
        "d1=pd.get_dummies(d1, columns=['E_PRGM_ACADEMICO'], prefix='E_PRGM')\n",
        "\n",
        "bool_cols = d1.select_dtypes(include=['bool']).columns\n",
        "d1[bool_cols] = d1[bool_cols].astype(int)"
      ],
      "metadata": {
        "id": "oz_CQ_729U4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_category_for_numbers(df, column_name, mapping_dict):\n",
        "    df[column_name] = df[column_name].map(mapping_dict)\n",
        "    return df\n",
        "\n",
        "mapping_dict = {\n",
        "    'bajo': 1,\n",
        "    'medio-bajo': 2,\n",
        "    'medio-alto': 3,\n",
        "    'alto': 4}\n",
        "d2=d1.copy()\n",
        "d2 = replace_category_for_numbers(d2, 'RENDIMIENTO_GLOBAL', mapping_dict)\n",
        "\n",
        "mapping_estrato = {\n",
        "    \"estrato1\": 1,\n",
        "    \"estrato2\": 2,\n",
        "    \"estrato3\": 3,\n",
        "    \"estrato4\": 4,\n",
        "    \"estrato5\": 5,\n",
        "    \"estrato6\": 6,\n",
        "    \"sinestrato\": 0\n",
        "}\n",
        "d2['F_ESTRATOVIVIENDA'] = (\n",
        "    d2['F_ESTRATOVIVIENDA']\n",
        "    .astype(str)\n",
        "    .str.strip()\n",
        "    .str.replace(\" \", \"\", regex=False)   # Eliminar espacios\n",
        "    .str.lower()\n",
        ")\n",
        "\n",
        "d2 = replace_category_for_numbers(d2, \"F_ESTRATOVIVIENDA\", mapping_estrato)\n",
        "#Se llenan casillas vacias con la moda de estrato\n",
        "d2['F_ESTRATOVIVIENDA'] = d2['F_ESTRATOVIVIENDA'].fillna(d4['F_ESTRATOVIVIENDA'].mode()[0])\n",
        "\n",
        "mapping_edu_padres = {\n",
        "    \"ninguno\": 0,\n",
        "    \"no aplica\": 0,\n",
        "    \"no sabe\": 0,\n",
        "    \"primaria incompleta\": 1,\n",
        "    \"primaria completa\": 2,\n",
        "    \"secundaria (bachillerato) incompleta\": 3,\n",
        "    \"secundaria (bachillerato) completa\": 4,\n",
        "    \"técnica o tecnológica incompleta\": 5,\n",
        "    \"tecnica o tecnologica incompleta\": 5,\n",
        "    \"técnica o tecnológica completa\": 6,\n",
        "    \"tecnica o tecnologica completa\": 6,\n",
        "    \"educación profesional incompleta\": 7,\n",
        "    \"educacion profesional incompleta\": 7,\n",
        "    \"educación profesional completa\": 8,\n",
        "    \"educacion profesional completa\": 8,\n",
        "    \"postgrado\": 9\n",
        "}\n",
        "\n",
        "d3=d2.copy()\n",
        "d3 = replace_category_for_numbers(d3, \"F_EDUCACIONMADRE\", mapping_edu_padres)\n",
        "d3 = replace_category_for_numbers(d3, \"F_EDUCACIONPADRE\", mapping_edu_padres)\n",
        "#Se llenan casillas vacias con 0\n",
        "d3['F_EDUCACIONMADRE'] = d3['F_EDUCACIONMADRE'].fillna(0)\n",
        "d3['F_EDUCACIONPADRE'] = d3['F_EDUCACIONPADRE'].fillna(0)\n",
        "\n",
        "def clean_text_column(df, column_name):\n",
        "    df[column_name] = (\n",
        "        df[column_name]\n",
        "        .astype(str)\n",
        "        .str.strip()\n",
        "        .str.lower()\n",
        "        .str.normalize('NFKD')\n",
        "        .str.encode('ascii', errors='ignore')\n",
        "        .str.decode('utf-8')\n",
        "        .str.replace('á', 'a')\n",
        "        .str.replace('é', 'e')\n",
        "        .str.replace('í', 'i')\n",
        "        .str.replace('ó', 'o')\n",
        "        .str.replace('ú', 'u')\n",
        "        .str.replace(r'[^a-z0-9\\s]', '', regex=True)\n",
        "        .str.replace(r'\\s+', '', regex=True)\n",
        "    )\n",
        "    df[column_name] = df[column_name].replace('nan', np.nan)\n",
        "    return df\n",
        "\n",
        "mapping_matri = {\n",
        "    'no pago matricula': 0,\n",
        "    'menos de 500 mil': 1,\n",
        "    'entre 500 mil y menos de 1 millon': 2,\n",
        "    'entre 1 millon y menos de 25 millones': 3,\n",
        "    'entre 25 millones y menos de 4 millones': 4,\n",
        "    'entre 4 millones y menos de 55 millones': 5,\n",
        "    'entre 55 millones y menos de 7 millones': 6,\n",
        "    'mas de 7 millones': 7\n",
        "}\n",
        "d4=d3.copy()\n",
        "d4 = clean_text_column(d4, 'E_VALORMATRICULAUNIVERSIDAD')\n",
        "d4 = replace_category_for_numbers(d4, 'E_VALORMATRICULAUNIVERSIDAD', mapping_matri)\n",
        "#Se llenan casillas vacias con la media\n",
        "d4['E_VALORMATRICULAUNIVERSIDAD'] = d4['E_VALORMATRICULAUNIVERSIDAD'].fillna(d4['E_VALORMATRICULAUNIVERSIDAD'].mean())\n",
        "\n",
        "mapping_work = {\n",
        "    '0': 1,\n",
        "    'menosde10horas': 2,\n",
        "    'entre11y20horas': 3,\n",
        "    'entre21y30horas': 4,\n",
        "    'masde30horas': 5,\n",
        "}\n",
        "d5=d4.copy()\n",
        "d5 = clean_text_column(d5, 'E_HORASSEMANATRABAJA')\n",
        "d5 = replace_category_for_numbers(d5, 'E_HORASSEMANATRABAJA', mapping_work)\n",
        "#Se rellenan casillas vacias con el promedio\n",
        "d5['E_HORASSEMANATRABAJA'] = d5['E_HORASSEMANATRABAJA'].fillna(d5['E_HORASSEMANATRABAJA'].mean())"
      ],
      "metadata": {
        "id": "jN5EtqK79p7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificar que todas las columnas sean numericas"
      ],
      "metadata": {
        "id": "Wa_L3K_7BuBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for columna in d5.columns:\n",
        "    valores_unicos = d5[columna].unique()\n",
        "    # Imprime el nombre de la columna y sus valores\n",
        "    print(f\"\\nColumna: {columna}\")\n",
        "    print(f\"Tipo de dato: {d5[columna].dtype}\")\n",
        "    print(f\"Total de valores únicos: {len(valores_unicos)}\")\n",
        "\n",
        "    # Muestra los valores  (se limitan a los primeros 10 para evitar saturar la consola)\n",
        "    print(f\"Valores Únicos: {valores_unicos[:10]}...\")"
      ],
      "metadata": {
        "id": "0Huhm_Ml8sQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bT1_4knZ3NGZ",
        "outputId": "701781bc-f003-4dbc-be7c-4e34d850cc8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 5) (1000,)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"train.csv\")\n",
        "df = dataset.sample(len(dataset))\n",
        "#d = dataset.iloc[:10000].sample(1000)\n",
        "X = df.drop(columns=['RENDIMIENTO_GLOBAL','ID'])\n",
        "y = df[\"RENDIMIENTO_GLOBAL\"].values\n",
        "print (X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rs_1j_LG3NGc"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import median_absolute_error, r2_score, mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQHbg-IH3NGr",
        "outputId": "c42eb079-580f-48e4-bc94-f0a8a3f9898b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--\n",
            "test score   0.473 (±0.0475) with 10 splits\n",
            "train score  0.347 (±0.0423) with 10 splits\n",
            "--\n",
            "test score   0.416 (±0.0335) with 10 splits\n",
            "train score  0.092 (±0.0213) with 10 splits\n",
            "--\n",
            "test score   0.486 (±0.0305) with 10 splits\n",
            "train score  0.483 (±0.0167) with 10 splits\n",
            "selecting  1\n",
            "\n",
            "selected model\n",
            "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=10,\n",
            "                      max_features=None, max_leaf_nodes=None,\n",
            "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                      min_samples_leaf=1, min_samples_split=2,\n",
            "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                      random_state=None, splitter='best')\n"
          ]
        }
      ],
      "source": [
        "zscores = []\n",
        "estimators = [estimator1, estimator2, estimator3]\n",
        "for estimator in estimators:\n",
        "    print(\"--\")\n",
        "    z = cross_validate(estimator, Xtv, ytv, return_train_score=True, return_estimator=False,\n",
        "                       scoring=rel_mrae, cv=ShuffleSplit(n_splits=10, test_size=val_size))\n",
        "    report_cv_score(z)\n",
        "    zscores.append(np.mean(z[\"test_score\"]))\n",
        "best = np.argmin(zscores)\n",
        "print (\"selecting \", best)\n",
        "best_estimator = estimators[best]\n",
        "print (\"\\nselected model\")\n",
        "print (best_estimator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoqTomjK3NGt"
      },
      "source": [
        "**PART 2**: train selected estimator on train/val, report performance on est"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPsMin_C3NGt",
        "outputId": "7b21451a-944d-4124-8fef-b59474c07255"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reported performance of selectd model 0.395\n"
          ]
        }
      ],
      "source": [
        "best_estimator.fit(Xtv,ytv)\n",
        "reported_performance = rel_mrae(best_estimator, Xts, yts)\n",
        "print (\"reported performance of selectd model %.3f\"%reported_performance)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "p38",
      "language": "python",
      "name": "p38"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}